{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3aFniNj6dyf"
   },
   "source": [
    "# LX 394 / 594 / 694 Homework 3\n",
    "\n",
    "The time has come to work through the steps we've been discussing in class with respect to the \"SHRDLU\"-like blocks-world manipulating robot.\n",
    "\n",
    "Some of this kind of recalls things that we talked about in class, and some of it goes beyond what we did in class.  At the end you'll have an opportunity to extend it a bit too. And it'll be a big benefit for understanding of some of the more complex semantics to have a chance to kind of puzzle through it on your own, even if some of it was kind of breezed through in the several classes that worked through this process.\n",
    "\n",
    "This is actually super super long.\n",
    "\n",
    "**Using the \"autograder\":** This is the same as last time. The way this notebook is set up is that you read a bunch of stuff, and then periodically you will be prompted to answer a question.  The question might take the form of a question you answer in prose, or (more often) a question you answer in code. The code questions come with a test that will check your answer.  If you have it correct, it will tell you that the question \"passed.\"  So, you can be fairly confident as you go along that you got the code working.  You'll want to submit a notebook where things pass.\n",
    "\n",
    "**Submitting at the end:** When you are ready to submit, download the `.ipynb` file and then go to Gradescope and upload it there.  The autograder will run and double-check your answers.  In principle there may be some tests (\"hidden tests\") that Gradescope runs that you didn't have access to when you were working through it.\n",
    "\n",
    "**Getting started**: In order for the checking procedure to work, you need to run this cell below first.  It will download the autograder stuff and the tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "YO6rRkW7N_24"
   },
   "outputs": [],
   "source": [
    "# Run this first, it makes the autograder go.\n",
    "# The \"%%capture\" line below keeps it from showing all the output\n",
    "%%capture\n",
    "# Install the autograder (otter-grader) and get the test files\n",
    "files = \"https://github.com/bucomplx/lx394s21/raw/main/assets/ipynb/hw3/tests.zip\"\n",
    "!pip install otter-grader && wget $files && unzip -o tests.zip\n",
    "# enable the otter test evaluator\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xsgd9Z1r5zd6"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydk4Qcv0bDZ_"
   },
   "source": [
    "# The goals\n",
    "\n",
    "At the outset, let's consider what we want to get out of this.  We are trying to model a little conversational device that has a domain of expertise (the shapes in a small two-dimensional world) and can converse in a limited way with a human about properties of those blocks, or do things to change the world around.\n",
    "\n",
    "This is largely about modeling knowledge, but it's also a chance to do some engineering work on how to display the world and get input from a human.  It gives us a chance to construct a grammar that is sophisticated enough to allow us to parse the sentences that we will need.\n",
    "\n",
    "So, to proceed we need several things, which we will walk through in turn.\n",
    "- A representation of the objects in the world, and their properties (including their current configuration)\n",
    "- A way to display the world\n",
    "- A syntactic grammar that can parse the sentences we want to interpret.\n",
    "- A semantic representation/grammar that will enable us to determine the truth conditions of a sentence\n",
    "- An input/output mechanism to allow us to talk to the robot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm2ozkOuUj50"
   },
   "source": [
    "# Setting up the model of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWfBtwXNUuI-"
   },
   "source": [
    "We will start by defining the model of the world, for this little blocks world.  The concept here is that there is a row of 8 squares that make up the floor, like a chess board, and there a few objects around that have colors and shapes.  The robot is represented by its hand, which can be holding an object or not, and is used to pick things up and put them down.\n",
    "\n",
    "NLTK has a \"semantics\" module that can help out with a number of aspects of this interpretation, provided we set up our world in a compatible way.  It is based on a standard way of evaluating semantics and logic from within the philosophical/semantics traditions.  If you wish to read the detailed documentation, it is here: [https://www.nltk.org/api/nltk.sem.html#module-nltk.sem]. The parts we are using are largely in the `logic`, `evaluate`, and `util` portions of the module.\n",
    "\n",
    "In order to use NLTK's semantics module, we set up a \"model\".  A model is defined by a \"domain of individuals\" (which is a list of all the things you can refer to) and a \"valuation function\", which represents the properties and relationships between the individuals.  The individuals in the domain are represented by short strings (like `\"a\"`, `\"b\"`, etc.), and the valuation function is mostly like a Python dictionary.\n",
    "\n",
    "> In class, we defined the domain of individuals first, and then moved on to define the valuation function.  However, once you have the valuation function, the domain of individuals is somewhat redundant, since you can infer the domain from the valuation function.  So, here we'll just define the valuation function and then infer the domain of individuals afterwards.\n",
    "\n",
    "Before we get started, let's do a little bit with actual Python dictionaries.  Suppose that we want to define a dictionary that has values for `'dana'`, `'chris'`, `'happy'`, and `'likes'`.  A dictionary is kind of like a list, except instead of referring to the elements by position, you refer to them by name.  The name of an element is known as its \"key\" and the element named is known as the \"value\".  Dictionaries are defined using curly braces around the outside, the key to the left of a colon, and the value to the right.  Values can be any kind of object (so, a set, a string, a number, whatever).  So here is our little dictionary that provides values for dana, chris, happy, and likes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "11q06cjTVEmB"
   },
   "outputs": [],
   "source": [
    "dict_example = {'dana': 'd', 'chris': 'c', 'likes': {('d', 'c')}, 'happy': {'c'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTsKvTf3VNUp"
   },
   "source": [
    "If we want to look up who has the property of being happy in this little world, we can use `'happy'` as the key to retrieve the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9warm7dQVW6h",
    "outputId": "6ba9d1d0-f0db-4e5c-c8ad-fa25c977d5ee"
   },
   "outputs": [],
   "source": [
    "dict_example['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHH4ysf3VdmY"
   },
   "source": [
    "If you iterate over a dictionary, the default behavior is to iterate over the keys, so we can print a list of all the terms that are defined in it by using a `for...in...` iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG8ZbzxSVqCP",
    "outputId": "2520de64-ff74-46d1-e917-fed63f90f90f"
   },
   "outputs": [],
   "source": [
    "for entry in dict_example:\n",
    "  print(\"Key is: \", entry, \" - value for entry is: \", dict_example[entry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0I9Vqy0V3kw"
   },
   "source": [
    "If we wanted to turn that dictionary into an official NLTK Valuation function, we can do this by converting the dictionary into a structure of pairs (where the key is the first element and the value is the second) and then instructing NLTK to build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YI6ec0g6WVir"
   },
   "outputs": [],
   "source": [
    "dict_example_tuple_version = list(dict_example.items())\n",
    "val_example = nltk.Valuation(dict_example_tuple_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eltzbfA6WkUy"
   },
   "source": [
    "We can use the Valuation object in much the same way as we used the dictionary we built it from, though it has some extra powers and uses that are provided by NLTK. So we can iterate over this to get the keys and values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UovZjQxTSIJ0",
    "outputId": "24f2e572-a537-4f4c-c8dc-ac6dde0f8673"
   },
   "outputs": [],
   "source": [
    "for entry in val_example:\n",
    "  print(\"Key is: \", entry, \" - value for entry is: \", val_example[entry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPGQo3raW7We"
   },
   "source": [
    "One thing to observe is that it has changed the format for \"happy\" slightly. Generally, an NLTK Valuation function will return either a (string representing a) single individual, or it will return a set of tuples.  For simplicity, NLTK just uses tuples for everything, whether it is a relation requiring a pair (like \"likes\") or just a property of single objects (like \"happy\").  So the entity listed as being \"happy\" there is a 1-tuple of just \"c\".  Conceptually, our original format (a set of individuals) is probably a bit closer to what we want, but NLTK has made a design decision to minimize the different types a Valuation function can return, and it is easy enough to turn a set of 1-tuples back into a set of individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHD18QfwXxyQ",
    "outputId": "a91efd3d-f301-4a3a-d4f3-1b60d68df0c9"
   },
   "outputs": [],
   "source": [
    "{x for (x,) in val_example['happy']} # set of the happy individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-uzowyVYD_U"
   },
   "source": [
    "We have a moderately elaborate scenario to describe, with several colors, several shapes, and a relationship between objects.  We could do it just as above, but NLTK provides a slightly easier way to define a Valuation function by writing it out in a string and then parsing it.  We'll use this.\n",
    "\n",
    "> It is worth noting that we are not required to build a Valuation function from a string.  We built a perfectly good Valuation function above without that.  It's just kind of clunky when the function gets large.  So, we will specify the Valuation function in a string and then ask NLTK to parse that into an actual Valuation function.  However, because we are asking NLTK to do that, we have to play by its rules as far as how the string is formatted. Specifically, it needs to have the keys on the left of a fat arrow (`=>`), sets on the right indicated with curly braces (`{...}`), pairs and tuples on the right indicated with commas and parentheses `(..., ...)`.\n",
    "\n",
    "Below we define `valstr` as a multiline string (surrounded by triple quotation marks) where each line represents one of the key-value pairings.  The symbol on the left of the fat arrow is an English word (because we are conducting this course in English), but it is not strictly speaking intended to be the language our sentences will eventually be written in.  These are the names of the properties and relationships.  Later in our grammar, we will define the semantic value of the word \"pyramid\" (an actual English word that might be in a sentence we are parsing) in terms of the symbol `pyramid` that we defined in our Valuation function.\n",
    "\n",
    "> To attempt to make this distinction a little bit clearer, I have defined the concept of \"odd\" (referring to the squares in the floor) by the name `oddtastic`.  When we get to the point of defining the grammar, we will define the English word \"odd\" in terms of the property named `oddtastic`.  The parser will not recognize the word \"oddtastic\" as being an English word, it will only recognize \"odd\".  My point in doing this is just to make it somewhat more evident that the words to the left of the fat arrows in the string specification are not supposed to be English, they are a kind of \"metalanguage\" name for the concept we are defining.\n",
    "\n",
    "The rest of the specification is probably familiar from repeated review in class, but in short: we have a floor made of blocks arranged so half of them are even and half are odd, we have a ball, two blocks, and two pyramids, each of which has a color, there are two named objects (dana and chris), and they are arranged so that there are three objects on squares and one object atop another.  Object \"`e`\" is not represented as being on anything because we will later assume that it is intially being held by the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6GhtboV1ZiSu"
   },
   "outputs": [],
   "source": [
    "# This is the specification of properties and relationships between individuals\n",
    "valstr = \"\"\"\n",
    "square => {s0, s1, s2, s3, s4, s5, s6, s7}\n",
    "oddtastic => {s1, s3, s5, s7}\n",
    "even => {s0, s2, s4, s6}\n",
    "block => {a, b}\n",
    "pyramid => {c, e}\n",
    "ball => {d}\n",
    "thing => {a, b, c, d, e}\n",
    "red => {a}\n",
    "blue => {b, e}\n",
    "green => {c, d}\n",
    "on => {(a,s1),(b,s2),(d,s4),(c,d)}\n",
    "dana => d\n",
    "chris => c\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNh2ppDYcH5L"
   },
   "source": [
    "We can then use this string to create a Valuation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wVvVg7UHSe22"
   },
   "outputs": [],
   "source": [
    "val = nltk.sem.Valuation.fromstring(valstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NkcnZYIcT8l",
    "outputId": "8d93c9da-9478-4452-e5cf-fc2adcfab2cb"
   },
   "outputs": [],
   "source": [
    "# double-check that it worked\n",
    "print(\"oddastic: \", val['oddtastic'])\n",
    "print(\"dana: \", val['dana'])\n",
    "print(\"on: \", val['on'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiInun66c2cW"
   },
   "source": [
    "When we are defining a model, we need to have both a Valuation function and a domain of individuals.  Now that our Valuation function is defined, we can ask NLTK to just figure out what the domain of individuals is, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXZn7XDRdAM-",
    "outputId": "83fe30d1-7f6e-4b2d-df13-e47356a73598"
   },
   "outputs": [],
   "source": [
    "print(val.domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUxh6WsWdmuB"
   },
   "source": [
    "It's not entirely obvious why, given that the domain of individuals is derivable from the Valuation function, we need to provide both when we ask it to construct a model. NLTK works in mysterious ways.  Anyway, to define the model (which is a machine NLTK can build that is capable of evaluating whether something is true or false within the world it models), we do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q154MBkEeJjB"
   },
   "outputs": [],
   "source": [
    "m = nltk.sem.Model(val.domain, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnARIFVvR19p"
   },
   "source": [
    "Another thing that we will need in order to actually evaluate whether a logical expression is true or false is to create an \"assignment function\" which, in effect, tells the interpreter what you are pointing at.  Let me take a quick second to illustrate this.  A basic assignment function in which you are not pointing to anything is created as below.  (\"g\" is the traditional name for an assignment function.)\n",
    "\n",
    "> I used `m.domain` instead of `val.domain` below.  Those are just two names for the same set of individuals.  For consistency, I will generally use `m.domain` once the model has been defined. Similarly, I will use `m.valuation` for the valuation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6-hIQ8TCdOS8"
   },
   "outputs": [],
   "source": [
    "g = nltk.Assignment(m.domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIp-RrzrfLtL"
   },
   "source": [
    "The arguments for `nltk.Assignment()` are the domain of individuals, and then any pointing functions.  So the reason that the definition of `g` above is an empty pointing is that it has specified the domain of individuals but then no pointing relations.  If we wanted to add a pointing gesture, we can add one as below.  Let's say that our first finger (which we will call `f1`) is pointing to individual `d` (which is the individual we named \"dana\").  So we add, as a second argument to `nltk.Assignment()`, a list of those pointings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AnRxMFANfgzu"
   },
   "outputs": [],
   "source": [
    "g2 = nltk.Assignment(m.domain, [('f1', 'd')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR_behPbggJw"
   },
   "source": [
    "When we are pointing with our first finger at dana, we can evaluate whether dana is green in either of the two ways below. The first is true if dana is green, the second is true if whatever we are pointing at with f1 is green.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwY4GTMIgpjf",
    "outputId": "ab5562da-3f35-4dc6-8b04-c59c14c18ccc"
   },
   "outputs": [],
   "source": [
    "expr = nltk.sem.Expression.fromstring(\"green(dana)\")\n",
    "print(m.satisfy(expr, g))\n",
    "\n",
    "expr = nltk.sem.Expression.fromstring(\"green(f1)\")\n",
    "print(m.satisfy(expr, g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHQd3dbfh0gF"
   },
   "source": [
    "Incidentally, if we print an assignment function, it will display what you are pointing at (in a pretty unintuitive format, but one that is commonly used in formal semantics). In square brackets after g, it will show an individual from the domain, a slash `/`, and then what is pointing to that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZfzv-z6hI_j",
    "outputId": "2b1c5db0-16d3-43db-9b9b-0929817fd0f0"
   },
   "outputs": [],
   "source": [
    "print(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8rfFooDqp4hV"
   },
   "source": [
    "### q1 (is that red thing a block?) ###\n",
    "\n",
    "**Question:** Now you try it.  Use an assignment function to point to the thing in our model of the world that is red (which you can determine just by looking at the string that specified the valuation function), and evaluate whether it is a block.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KwNgM7op4hc",
    "outputId": "fc025f20-0230-4277-b8e9-7e23f9c26914"
   },
   "outputs": [],
   "source": [
    "# define an assignment function that points to the red thing\n",
    "g3 = ...\n",
    "# define expr like above except checking for being a block rather than being green\n",
    "expr = ...\n",
    "print(\"The red thing is a block? \", m.satisfy(expr, g3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGCZClRQizM3"
   },
   "source": [
    "Ok, back to the thread.  We can anticipate that we are going to be changing this world around eventually, and it would be nice to have a way to reset it back to its original configuration.  So we will at this point define a function called `reset_world()` that will redefine the Valuation function, define the empty assignment function, and also define `obj_in_hand` (what the robot is holding) to be object \"e\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_fEpmjLZhzpZ"
   },
   "outputs": [],
   "source": [
    "def reset_world():\n",
    "  global valstr, g, m, obj_in_hand\n",
    "  val = nltk.Valuation.fromstring(valstr)\n",
    "  m = nltk.Model(val.domain, val)\n",
    "  g = nltk.Assignment(m.domain)\n",
    "  obj_in_hand = 'e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bCpTVCVjqmm"
   },
   "source": [
    "Now, whenever we want to reset things to a known starting configuration, we can just execute `reset_world()`.\n",
    "\n",
    "> The function above has a line that ensures that the variables being defined are in the global (notebook) space, so that the values are visible to our other functions.  (Had we not done this, some of the values assigned would have only been visible within the function, which would not have been very useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jX5xb9mUjlq9"
   },
   "outputs": [],
   "source": [
    "reset_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuzd3OJUKT9W"
   },
   "source": [
    "The other thing in this world besides the blocks and floor is the robot.  The robot in this world will be represented by a hand.\n",
    "\n",
    "At this point, there are some architectural/engineering decisions to make.  I went a particular way in class, but that wasn't forced.  The goal is to represent a robot that can hold things, pick them up, put them down.  In order for us to specify how this robot interacts with the world, we will need to keep track of what the robot is holding.  Since the model has a record of the current configuration (by virtue of having a record of what things are on what other things), it seemed rational to do what I did in class, and consider being held by a robot hand as being part of the current configuration as well.  But it didn't have to be represented that way, and we'll do it differently here just to illustrate that.\n",
    "\n",
    "There are no laws of physics in this model of the world, no consistency checks to ensure that two objects are not occupying the same space, nothing that ensures that if c is on d, d is not also on c.  We just have a list of properties and relationships.  Because the \"on\" relationship refers to a physical configuration, we can't translate that into a physical world where things are mutually on one another. But if we had been talking about a \"likes\" relationship, there might be plenty of examples where two individuals mutually like each other.  The model doesn't know what is a physical relation and what is an emotional one.\n",
    "\n",
    "All that is to say that we could have kept track of the robot separately from the world, rather than introduce the property \"held\" into the model.  So, just for variety, we'll make a different architectural choice here, and keep the robot outside the world.  Meaning that model doesn't know what is being held, only the robot will know that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OfWqJYDNr5i"
   },
   "source": [
    "# Finding the properties of an object\n",
    "\n",
    "One thing we will need to be able to do is work out what properties an object has.  We at least need to be able to do this in order to know what color and shape to use when drawing an object, but this is also something that we will need to be able to look at when we are trying to resolve reference as well.\n",
    "\n",
    "As defined, the model knows, for each property, which objects have that property.  What we are trying to do now is determine, for a given object, what properties does it have? It's kind like just turning the lookup table 90 degrees.  \n",
    "\n",
    "As a reminder, we can walk through the valuation function like we walk through a dictionary.  The code below prints, for each key, what value is associated with that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNbdpv_-Og21",
    "outputId": "c4004d42-c116-40a9-b6f4-dd8ea42e85d1"
   },
   "outputs": [],
   "source": [
    "# this will walk through the keys (words) in the valuation function and print\n",
    "# what value each one refers to.\n",
    "for v in m.valuation:\n",
    "  print(v, \": \", m.valuation[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "390ABmJXtn-Y"
   },
   "source": [
    "Looking over these properties, there are basically three circumstances.  Suppose we are asking about the properties of `c`.  The terms that involve `c` are: a name (`chris`), some one-place properties (`green`, `pyramid`, `thing`), and a relation (`on`).\n",
    "\n",
    "When we draw the world and when we are resolving referents, we will need to know the one-place properties for color and shape.  We are going to need to determine what is on an object as well, in order to work out the spatial configurations.  But for the moment, let us focus in just on the 1-place properties.  We'll define something more specific in the next section to check the \"on\" relation.\n",
    "\n",
    "What we want to do, then, is look at the terms defined by the valuation function and, for any of those that are 1-place predicates, look to see if a particular individual object has the property.  This means we need a way to determine what is and is not a 1-place predicate.  Looking at them, we can see that a 1-place predicate (like \"blue\") is a set of tuples, where each tuple has a single member.  So, let's just define something that is true of 1-place predicates and not of other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5_2dVhrbykDp"
   },
   "outputs": [],
   "source": [
    "def simple_property(p):\n",
    "  if type(p) == set:\n",
    "    element = list(p)[0]\n",
    "    if type(element) == tuple:\n",
    "      if len(element) == 1:\n",
    "        return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YXubk8DzRPN",
    "outputId": "5fc848b3-eb87-4d97-fb56-e5ed1758e7cc"
   },
   "outputs": [],
   "source": [
    "print(\"Red a 1-place predicate: \", simple_property(m.valuation['red']))\n",
    "print(\"On is a 1-place predicate: \", simple_property(m.valuation['on']))\n",
    "print(\"Dana is a 1-place predicate: \", simple_property(m.valuation['dana']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz73U5eBzwWE"
   },
   "source": [
    "We can then just define the set of terms that includes only the 1-place predicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_J_TC6ncz6ox",
    "outputId": "c4dc0742-d86e-4b21-e0ff-c794049c5b63"
   },
   "outputs": [],
   "source": [
    "{p for p in val if simple_property(m.valuation[p])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw8uxSfl0IzC"
   },
   "source": [
    "And then we can define a function that will return any of those 1-place predicates that hold of a given object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GWUyfRqU0QOI"
   },
   "outputs": [],
   "source": [
    "def obj_properties(obj):\n",
    "  global m\n",
    "  simple_properties = {p for p in m.valuation if simple_property(m.valuation[p])}\n",
    "  return {p for p in simple_properties if (obj,) in m.valuation[p]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubcR0VCI0ye9"
   },
   "source": [
    "Did it work? Let's try it for 'd'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_wtlkfn01Y2",
    "outputId": "091b7c06-f086-41c0-9b28-c19d2397e57f"
   },
   "outputs": [],
   "source": [
    "obj_properties('d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8anQnyq1doM"
   },
   "source": [
    "As an artistic aside, we can make the `simple_property()` function much more compact, by using short-circuit evalution. For fun, you can work out how this does the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofFQGC4c1o8-",
    "outputId": "5863985f-c2e5-4dd9-9df1-9253be82d2f1"
   },
   "outputs": [],
   "source": [
    "def simpler_property(p):\n",
    "  return type(p) == set and type(list(p)[0]) == tuple and len(list(p)[0]) == 1\n",
    "\n",
    "print({p for p in m.valuation if simpler_property(m.valuation[p])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7g6RR0qaRTp"
   },
   "source": [
    "# Preparing for drawing the world\n",
    "\n",
    "Beyond knowing what shape and color everything is, we also need to be able to figure out where everything is.  The representation of the world we set up doesn't know that; it only knows what things are on what other things.  We happen to know (by assumption, outside the model) where the squares are in the floor: they are in a line at the bottom.  So in order to figure out where the other objects are, we need to figure out where they are relative to those squares.\n",
    "\n",
    "We will do this by working our way along the floor, one square at a time, and asking what is on that square (and, if something is on the square, asking what is on that thing, and so on, until we reach the top of the stack of things on a square).\n",
    "\n",
    "The most basic thing we need to be able to do in order to implement this is to find out, given an object, what (if anything) is on that object.  We need a function that can tell us \"what's on\" something.  We'll use an assignment function for this, to point at the thing and asking the model \"what individuals are on that thing we're pointing at?\"\n",
    "\n",
    "To do this we will use the `satisfiers()` function that the model provides.  To use it, you give it an expression with a variable (like `x`) in it, and you ask \"what are the individuals that would lead this expression to be true if we substituted them in for `x`?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4BdjOgCQNx9",
    "outputId": "90793fb2-9dfa-4452-de28-831ed2029979"
   },
   "outputs": [],
   "source": [
    "g2 = nltk.Assignment(m.domain, [('f1', 'd')])\n",
    "expr = nltk.sem.Expression.fromstring(\"on(x, f1)\")\n",
    "print(list(m.satisfiers(expr, 'x', g2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO4f003ZQpWb"
   },
   "source": [
    "So, that told us that the things that stand in the \"on\" relation to \"d\" are: c.  Perfect.  So, let's generalize/package this into a function.  Inside this function we will use `try...except` because NLTK will halt with an error if we ask it what's on a thing when that thing has nothing on it.  We don't want it to stop in that circumstance, we just want it to tell us that we are now at the top of its stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GwLfNA_P79RM"
   },
   "outputs": [],
   "source": [
    "def whats_on(obj):\n",
    "  global m\n",
    "  # point at the current support and ask: what is on that?\n",
    "  g2 = nltk.Assignment(m.domain, [('f1', obj)])\n",
    "  expr = nltk.sem.Expression.fromstring(\"on(x, f1)\")\n",
    "  try:\n",
    "    supported_object = list(m.satisfiers(expr, 'x', g2))[0]\n",
    "  except:\n",
    "    supported_object = None\n",
    "  return supported_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mD51lfeYCQt"
   },
   "source": [
    "Now, we want to use this to construct a representation of what is stacked on each of the squares.  Minimally, there will be the supporting square at the bottom, but there might be other things on that square.  Square `s4` happens to have a couple of things on it, so let's build that stack by hand, and then we'll make a function that will do it in general.\n",
    "\n",
    "At the outset, our \"stack so far\" is empty.  And then we will add the support square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MM8u9TSiYe6q",
    "outputId": "3d11e223-39d6-46f9-cf2d-f6a28946e791"
   },
   "outputs": [],
   "source": [
    "# at the beginning, nothing in the stack.\n",
    "stack = []\n",
    "\n",
    "# we will add the support square next\n",
    "next_obj = 's4'\n",
    "stack.append(next_obj)\n",
    "\n",
    "# now, what is on that thing we just added?\n",
    "# (that will be the next thing we will want to add to the stack)\n",
    "next_obj = whats_on(next_obj)\n",
    "print(\"The stack is currently: \", stack)\n",
    "print(\"The next object for the stack is: \", next_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTaZG_2MZN2M"
   },
   "source": [
    "Notice what we did with `next_obj`.  We added it to the `stack` list, asked `whats_on` it, and then redefined `next_obj` to be whatever that result was.  The idea is that we keep using `next_obj` to mean \"the next thing to add to the `stack` list\".\n",
    "\n",
    "The benefit of having done it that way is that we can just repeat the exact thing we just did in order to extend the stack to the next level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duhSWLffZX1w",
    "outputId": "190da28b-43b4-432e-f7da-db32a2a743e6"
   },
   "outputs": [],
   "source": [
    "stack.append(next_obj)\n",
    "next_obj = whats_on(next_obj)\n",
    "print(\"The stack is currently: \", stack)\n",
    "print(\"The next object for the stack is: \", next_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-tJPvtjZeeg"
   },
   "source": [
    "And then we can repeat the same exact thing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQqn_mooZ8Pw",
    "outputId": "cf4fa6d8-702d-401a-929c-8fc4db1b15cd"
   },
   "outputs": [],
   "source": [
    "stack.append(next_obj)\n",
    "next_obj = whats_on(next_obj)\n",
    "print(\"The stack is currently: \", stack)\n",
    "print(\"The next object for the stack is: \", next_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWHLCRtRast_"
   },
   "source": [
    "And we've reached the top (which we know because `next_obj` is now `None`).\n",
    "\n",
    "Now, let's make a function to do this for us.  All it is going to do is just do that same `append`...`whats_on()` step over and over, so long as `next_obj` is not `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NB_pVZwuOmtz"
   },
   "source": [
    "### q2 (build_stack) ###\n",
    "\n",
    "**Question:** Finish up the function below.  Make it do the same thing we just did by hand.  This is borderline trivial if you have been following along. You will add two lines inside the `while` block.  (The lines inside the `while` block will be executed so long as `next_obj` is not `None`, and when `next_obj` is `None` it will stop, and head back out to `return stack`.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "1Wru5bRM8dMB"
   },
   "outputs": [],
   "source": [
    "def build_stack(square):\n",
    "  stack = []\n",
    "  next_obj = square\n",
    "  while next_obj:\n",
    "    ...\n",
    "    next_obj = ...\n",
    "  return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae4TFxIMfjbJ"
   },
   "source": [
    "Success!  So, now that we can build one stack, we can build a stack for each one of the squares.\n",
    "\n",
    "At this point, let's impose some \"physical\" constraints on the world.  We're going to line up the squares along the floor in numerical order, so that they represent the horizontal position in this 2-dimensional world.  So, we will define the \"floor\" as being that list of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSgUZILak5iA",
    "outputId": "6ce5d63e-a0fc-4990-c627-aaf7668d511c"
   },
   "outputs": [],
   "source": [
    "floor = [\"s{}\".format(n) for n in range(8)]\n",
    "print(floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um1XH3QXk9X2"
   },
   "source": [
    "And now we make a list of the stacks on each of the squares of the fllor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "z026hAVlIUGt"
   },
   "outputs": [],
   "source": [
    "stacks = [build_stack(s) for s in floor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCVLiVQFIgUu",
    "outputId": "fd32d01c-aaa5-4f2e-910d-9d1e24ff96fe"
   },
   "outputs": [],
   "source": [
    "stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YokD5dEPf0ED"
   },
   "source": [
    "And with that, we now have a position for everything, and so we can proceed to draw `stacks` in a slightly more colorful and informative way (though, actually, even just the display above mostly works fine, you just need to tip your head to the side and remember what colors and shapes things are supposed to be)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dkhh_MbzhVOs"
   },
   "source": [
    "# Drawing the world\n",
    "\n",
    "We will use the plotting module `matplotlib` to draw the graphics.  We get this online by running the following commands.  The first one instructs matplotlib to put the graphics here in the document, the `import` command makes Python aware of its commands (and gives us a typing shortcut, we can just refer to `plt` instead of `matplotlib.pyplot`).  The `import Wedge` command makes Python aware of the `Wedge` command we are using to draw the robot hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "MMOQtVB_3zrW"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Wedge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Jagc2AaibZo"
   },
   "source": [
    "As for drawing each shape itself and the world as a whole, we kind of talked through it in class, and this function is very similar to the one developed in class.  This version is slightly better in a couple of ways, but we won't dwell on it here.  You can look through it if you want, but we will mostly just use it to draw the world without looking closely at how it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "QFNEzzlpjbC-"
   },
   "outputs": [],
   "source": [
    "def draw_shape(obj, col, row):\n",
    "  \"\"\"\n",
    "  Draw an obj (using its color and shape properties) at col, row\n",
    "  \"\"\"\n",
    "  # define the space in a cell that an object takes up (90% of height and width)\n",
    "  side = .9\n",
    "  half = side / 2\n",
    "  # get the properties of the object\n",
    "  properties = obj_properties(obj)\n",
    "  # figure out the color, assume blue if it isn't red or green\n",
    "  if 'red' in properties:\n",
    "    color = 'red'\n",
    "  elif 'green' in properties:\n",
    "    color = 'green'\n",
    "  else:\n",
    "    color = 'blue'\n",
    "  # draw the right shape\n",
    "  if 'ball' in properties:\n",
    "    patch = plt.Circle( (col+half, row+half), half, fc=color)\n",
    "  elif 'pyramid' in properties:\n",
    "    patch = plt.Polygon( ((col, row), (col+half, row+side), (col+side, row)), fc=color)\n",
    "  elif 'square' in properties:\n",
    "    # squares can be even or not (odd), so make the crosshatch pattern correspond\n",
    "    if 'even' in properties:\n",
    "      pattern = '//'\n",
    "    else:\n",
    "      pattern = '\\\\\\\\'\n",
    "    patch = plt.Rectangle((col, row), side, side, fc='purple', ec='cyan', hatch=pattern)\n",
    "  elif 'block' in properties:\n",
    "    patch = plt.Rectangle((col, row), side, side, fc=color)\n",
    "  else: # hand\n",
    "    patch = Wedge((col+1, row + half), half, 30, 330, fc='yellow', ec='black')\n",
    "  plt.gca().add_patch(patch)\n",
    "  plt.gca().annotate(obj, (col+half, row+half), va='center', ha='center', color='white', weight='bold', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0QN0-vlQJF7"
   },
   "source": [
    "Similarly, we'll just define `plot_world()` without much comment.  It was described in class, and this is mostly just the same as it was in class.  It differs a little bit because we are now keeping track of what the robot is holding using the (global) variable `obj_in_hand` rather than making \"held\" be a property that individuals have in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zvA3RFAymgu4"
   },
   "outputs": [],
   "source": [
    "def plot_world():\n",
    "  \"\"\"\n",
    "  draw the whole blocks world by drawing the stack on each square,\n",
    "  the held object, and the hand\n",
    "  \"\"\"\n",
    "  global floor, obj_in_hand\n",
    "  # prepare the canvas\n",
    "  plt.axes()\n",
    "  # determine what the piles are on each of the squares\n",
    "  stacks = [build_stack(s) for s in floor]\n",
    "  # find the tallest pile (for use in positioning the hand)\n",
    "  tallest = max( [len(s) for s in stacks] )\n",
    "  # draw the held object if there is one\n",
    "  if obj_in_hand:\n",
    "    draw_shape(obj_in_hand, 1, tallest+1)\n",
    "  # draw the hand itself (shape designation is None)\n",
    "  draw_shape(None, 0, tallest + 1)\n",
    "  # go through the columns\n",
    "  for col in range(8):\n",
    "    stack = stacks[col]\n",
    "    # walk up the stack in this column, drawing each shape\n",
    "    for row, obj in enumerate(stack):\n",
    "      draw_shape(obj, col, row)\n",
    "  # scale the axes so that everything fits on the screen\n",
    "  plt.axis('scaled')\n",
    "  # show the final result\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "PZSfjKkKIja4",
    "outputId": "9861657e-c657-4369-f1f5-033e5ecbb0af"
   },
   "outputs": [],
   "source": [
    "plot_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf4AvqIXqARZ"
   },
   "source": [
    "# Affecting the world\n",
    "\n",
    "\n",
    "The main things we want our robot to do is pick up objects and put them down on other objects.  Before we get into parsing input, let's define some functions that can do these things.\n",
    "We will start by considering putting an object down.  Since we know what the robot is holding, the information we need is what object to put it on.  What it means to put an object on another one is to take it out of the hand, and add an \"on\" relation to the valuation function.\n",
    "\n",
    "We will not do much by way of sanity checking here, since we will do most of that elsewhere.  We will assume that if we use the `put_on()` and `pick_up()` functions we defined below, that we are already sure that, e.g., the robot has something in its hand to put down, that the target is visible, etc.  We will just be doing the picking up and putting down here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PMJQvYTfsbzR"
   },
   "outputs": [],
   "source": [
    "def put_on(target):\n",
    "  global obj_in_hand, m\n",
    "  m.valuation['on'] |= {(obj_in_hand, target)}\n",
    "  obj_in_hand = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "M9GNcZ0WxO9U",
    "outputId": "886b6bf1-8c33-46ac-bd3a-2e3e00fdf921"
   },
   "outputs": [],
   "source": [
    "reset_world()\n",
    "plot_world()\n",
    "put_on('a')\n",
    "plot_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUpj2UiDxNI9"
   },
   "source": [
    "The other thing we want the robot to do is to pick things up.  Again, no sanity checks here, we will assume that the object to be picked up is already determined to be visible, that the robot isn't already holding anything, etc.  We will just implement the picking up part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "VjHTGTl-x2Bi"
   },
   "outputs": [],
   "source": [
    "def pick_up(obj):\n",
    "  global obj_in_hand, m\n",
    "  m.valuation['on'] = {(x,y) for (x,y) in m.valuation['on'] if x != obj}\n",
    "  obj_in_hand = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "M2G-dSFxylmw",
    "outputId": "95887ff2-536e-429b-bc3b-1efd98be7cc6"
   },
   "outputs": [],
   "source": [
    "reset_world()\n",
    "put_on('s7')\n",
    "pick_up('c')\n",
    "plot_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aIttA3r0UUp"
   },
   "source": [
    "# Building a grammar\n",
    "\n",
    "Now we will build a grammar that will allow us to parse a small set of sentences about the world.  NLTK provides some tools for this.  If we define a grammar that specifies how words and constituents can be organized into hierarchical tree structures, and how the semantics of each is defined and is combined, then it can largely just do the rest for us. So we will define the grammar.\n",
    "\n",
    "As a preliminary setup step, let's also make the `svgling` package available, which allows us to be able to draw the tree structures. I will do this without much comment, I did talk through a little of this in class.  It basically installs `svgling`, `import`s it so that Python is aware of the commands it provides, and then defines a function called `convert_tree()` that takes an NLTK-generated tree and turns it into a simpler structure that `svgling` knows how to draw.  In the process the `SEM` (semantic value) features and `CT` (clause type) reatures will be drawn as part of the node label for any node that has those features defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--igUvNe1a46",
    "outputId": "b6244afd-32d1-46cf-e0e8-f8549fdf1f9f"
   },
   "outputs": [],
   "source": [
    "# install tree drawing package svgling\n",
    "!pip install svgling\n",
    "import svgling\n",
    "\n",
    "# define a function to convert a feature tree into something svgling can display\n",
    "def convert_tree(tree, features=True):\n",
    "  \"\"\"\n",
    "  convert a feature tree into a simple tree that svgling can draw\n",
    "  \"\"\"\n",
    "  nodetype = type(tree).__name__\n",
    "  if nodetype == 'Tree':\n",
    "    keylist = list(tree.label().keys())\n",
    "    label = tree.label()[keylist[0]]\n",
    "    if features:\n",
    "      if 'SEM' in tree.label():\n",
    "        label += \"\\n\" + str(tree.label()['SEM'])\n",
    "      if 'CT' in tree.label():\n",
    "        label += \"\\n\" + str(tree.label()['CT'])\n",
    "    return tuple([label] + [convert_tree(node, features) for node in tree])\n",
    "  else:\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBmoAr2h1k9j"
   },
   "source": [
    "There is an engineering/architecture decision made here at the beginning, which I made in class as well.  It is not crucial, and perhaps it is more confusing than useful, but here is the idea:\n",
    "\n",
    "The grammar is specified with a string that is a lot like the `valstr` string that we used earlier in order to define the Valuation function.  The grammar we will define has a lot of different parts that are largely independent, and I would like to develop the grammar somewhat step by step, and allow for redefining just parts of it while leaving the rest alone.  We could of course just keep modifying a big long grammar-specification string and then using that to define an NLTK grammar, but it seemed a bit more comprehensible to use a Python dictionary to hold the independent parts, and then just assemble the various parts together into a big string right before we use it to create the grammar object.\n",
    "\n",
    "A quick simple demonstration of the idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vyGmq1gL2eAr"
   },
   "outputs": [],
   "source": [
    "simple_dictionary = {'first': 'A first bit', 'second': 'Bit number 2', 'prologue': 'Start here'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nC3WFDFs2tXd",
    "outputId": "5793fc44-bdef-4ff0-c23b-744d801cb19b"
   },
   "outputs": [],
   "source": [
    "print(simple_dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "911X04sH29Yp",
    "outputId": "cc54617a-fdd3-4833-fd72-479385aee67a"
   },
   "outputs": [],
   "source": [
    "print(sorted(simple_dictionary.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFWkKYIp3B0B",
    "outputId": "e48931bf-0288-4f8b-fe2c-2ac52e06f4d6"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(sorted(simple_dictionary.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pfvn32U63Sd_"
   },
   "source": [
    "That last step creates a string that is built from each of the values in the dictionary, sorted in alphabetical order, and separated by a linebreak (`\"\\n\"`).  You can see that when it is sorted, it goes alphabetically by the value itself (not the alphabetic order of the keys, which would have been `first`, `prologue`, `second`).  The sorting is important because NLTK requires that the first line of a grammar be `% start S` to indicate that the top node of the tree should be the symbol `S`.  It turns out that the character `%` will sort before any alphabetic letters, so by sorting the values we ensure that the `% start` line is right at the top of the string we will build the grammar from.\n",
    "\n",
    "We will define a function that will do this for us, if we give it a dictionary specifying a grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oShECDwj4bwr"
   },
   "outputs": [],
   "source": [
    "def assemble_spec(gramspec):\n",
    "  return \"\\n\".join(sorted(gramspec.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aB-XbQmE4p1S",
    "outputId": "8969885c-259f-43d5-95cd-576ad4d49000"
   },
   "outputs": [],
   "source": [
    "# this is just to show that assemble_spec does what we just did.\n",
    "print(assemble_spec(simple_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUL3THV24vE1"
   },
   "source": [
    "Now on to the grammar.  We bring in NLTK's grammar functions, and then start defining parts of the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "4h4mPNgw41nz"
   },
   "outputs": [],
   "source": [
    "from nltk import grammar\n",
    "\n",
    "gramspec = {}\n",
    "\n",
    "gramspec['s'] = r\"\"\"\n",
    "% start S\n",
    "S[SEM=<?subj(?vp)>] -> DP[SEM=?subj] VP[SEM=?vp]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgm-OA2m532w"
   },
   "source": [
    "This is defining the very top of the tree, and what it says is: a) the very top node of the tree is `S`, and b) an `S` node is made of a `DP` and `VP`.  That is, a sentence has a subject and a predicate.\n",
    "\n",
    "The rule looks a bit complex because it covers both the syntactic combination and the rules for combining the semantics. Without the semantics part, the rule is just:\n",
    "\n",
    "```\n",
    "S -> DP VP\n",
    "```\n",
    "\n",
    "Where the `DP` is the subject of the sentence and the `VP` is the verb phrase.  The `[SEM=...]` parts tacked onto each of the node labels define how the semantics of the subject and VP combine to yield the semantics of the whole sentence.\n",
    "\n",
    "> Rules of this type are known in theoretical syntax as \"rewrite rules\" or \"phrase structure rules\" and the concept is like this: if you have an `S` then you are allowed to rewrite that `S` as `DP` and `VP`.  The trees that we are familiar with from syntax can then be viewed as a record of the applications of these rewrite operations.  We will then have other rules that indicate how a `VP` and `DP` can be rewritten, etc.\n",
    ">\n",
    "> In addition to specifying how the syntactic constituency works, it also specifies how the semantics combines.  Every node can have a label and any number of features.  The label is the `S` or `DP` or `VP`.  The features are specfied within square brackets after the label.  Conventionally, the feature's name will be an abbreviation in capital letters, followed by `=`, and then the value that feature has.  If a feature's value starts with `?` then it is a variable, and this has a different meaning on the left side of the arrow and on the right side of the arrow.  On the right side of the arrow, something like `SEM=?vp` means \"whatever value the SEM feature has here, call it `?vp`\" -- and then on the left side of the arrow, `?vp` means \"use whatever value we'd assigned to `?vp` over on the right side of the arrow\".  It's like defining a function and naming the arguments; the names are defined on the right side of the arrow, and are used on the left side of the arrow.  So what this `S` rule says with respect to the semantics is that the `SEM` feature of `S` is going to be whatever (function) the `DP` node refers to, applied to whatever (argument) the `VP` node refers to.  The value on the left is enclosed in angled brackets to indicate that it is an expression that needs to be evaluated.\n",
    "\n",
    "In a way, the syntax and semantics are operating in different directions.  The syntax part is operating top-down.  It says: starting with `S`, rewrite things until we get down to the words that match the sentence.  The semantics starts at the bottom, with the idea that the semantic value of a constituent can be derived from the semantic values of the parts that make it up.  Together, they will provide a hierarchical parse of a sentence that has both syntax and semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shOKq0uy9KhX"
   },
   "source": [
    "Let's keep going so that we can get to a point where we can parse a sentence.  I'm going to just define some stuff here, and we'll come back to why it is defined that way once there is a tree to look at.\n",
    "\n",
    "Even though we are going to go through it a bit more below, I will just mention here: we are defining two names, a VP that consists of the verb \"is\" and a PP, a PP that consists of a P and an object, and the preposition \"on\".\n",
    "\n",
    "One thing to observe is that we are defining two rules of the form\n",
    "```\n",
    "DP -> ...something...\n",
    "```\n",
    "These are interpreted as options.  If there is a DP in the structure being derived, then either one of those rules can be applied at that point.  Later on, we will have even more rules with DP on the left side.  But here, one could expand the DP as 'dana' or one could expand the DP as 'chris'.  Either one is legitimate.  The grammar as a whole defines all of the sentences you *can* get to by starting with S and using some combination of rewrite rules until you're down to the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3L2j0Zoa8Oyn"
   },
   "outputs": [],
   "source": [
    "# A DP can be rewritten as \"dana\", in which case the semantics\n",
    "# should be: \"those properties true of dana\".  Likewise for \"chris\".\n",
    "gramspec['names'] = r\"\"\"\n",
    "DP[SEM=<\\P.P(dana)>] -> 'dana'\n",
    "DP[SEM=<\\P.P(chris)>] -> 'chris'\n",
    "\"\"\"\n",
    "\n",
    "# A VP in this limited grammar is made of a copula (the verb \"is\")\n",
    "# and a PP (which will wind up being \"on\" something).\n",
    "# The VCOP has no contribution to make to the semantics, the VP\n",
    "# just has exactly the same semantics that the PP within it has.\n",
    "\n",
    "gramspec['vp'] = r\"\"\"\n",
    "VP[SEM=?pp] -> VCOP PP[SEM=?pp]\n",
    "VCOP -> 'is'\n",
    "\"\"\"\n",
    "\n",
    "gramspec['pp'] = r\"\"\"\n",
    "PP[SEM=<?p(?dp)>] -> P[SEM=?p] DP[SEM=?dp]\n",
    "\"\"\"\n",
    "\n",
    "# the semantics of \"on\" here are actually pretty complicated,\n",
    "# we will work through that in a bit.\n",
    "gramspec['p'] = r\"\"\"\n",
    "P[SEM=<\\X x.X(\\y.on(x,y))>] -> 'on'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "250lCOchVmXr"
   },
   "source": [
    "We have now defined a few fragments of this grammar. We've called those fragments 's', 'names', 'vp', 'pp', and 'p'. Let's assemble them together to see what we have as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9KkBju8-pQ4",
    "outputId": "6fd184c7-2dcf-45ff-d9c2-217641a02fca"
   },
   "outputs": [],
   "source": [
    "print(assemble_spec(gramspec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnCTkzSyV9yB"
   },
   "source": [
    "That's just enough to parse \"chris is on dana\". So, let's do that just to see this in action.\n",
    "\n",
    "To use this grammar we have specified, we:\n",
    "- assemble it into a string as above\n",
    "- use that string to build the grammar\n",
    "- use the resulting grammar to build a parser\n",
    "- ask the parser to generate a machine that can parse this specific sentence\n",
    "- convert this into a list (which is what actually makes the machine run, and parse the sentence)\n",
    "- take the first parse of the sentence, convert the tree into something `svgling` can draw\n",
    "- draw it (by letting the value of `draw_tree()` be displayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "zyhPdCyvWY2v",
    "outputId": "7b97f95f-fa52-4fbe-8d65-71c126311b9e"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"chris is on dana\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo-K8tlYX6aM"
   },
   "source": [
    "Now, compare the tree to the grammar. Look at the PP node, it has a `SEM` feature of `\\x.on(x,dana)` which is a function that takes an individual as its argument, calls it `x`, and the returns true if that individual we called `x` is on dana.  Put another way, it represents the individuals that are on dana, it is true of all of those individuals and false of any others.\n",
    "\n",
    "If you look above at the `VP` rule, you can see how it got from the `PP` node to the `VP` node.  To save you from scrolling back up, this was the VP rule:\n",
    "```\n",
    "VP[SEM=?pp] -> VCOP PP[SEM=?pp]\n",
    "```\n",
    "The `VP` consists of a `VCOP` and ` PP`.  The `VCOP` can be rewritten as 'is'.  The `SEM` feature of the `VP` is just `?pp`, which is whatever the `PP`'s `SEM` feature was.  And in the tree you can see that indeed, the `VP`'s `SEM` feature is that same function, true of individuals that are on dana and false of any others.\n",
    "\n",
    "To see how it got from `VP` to `S` is a bit trickier. Look at the `S` rule.\n",
    "```\n",
    "S[SEM=<?subj(?vp)>] -> DP[SEM=?subj] VP[SEM=?vp]\n",
    "```\n",
    "It says that the `SEM` feature of `S` is derived by taking the function represented by the `SEM` feature of the subject (`?subj`) and applying it to the `SEM` feature of the `VP` (`?vp`).  So what is the function that the subject represents?\n",
    "\n",
    "In the tree above (and in the rule) we can see that it is `\\P.P(chris)`. That is, given a predicate, the function returns true if the predicate holds of chris.  It represents all the properties that chris has.  In the `S` rule, this function is applied to the value of the `SEM` feature of `VP`.  The `SEM` feature of `VP` is, again, \"on dana\"; it is true of any individual that is on dana.  It is the property of being on dana.\n",
    "\n",
    "So, combining these means that we take the property of being on dana and give it to the function that is true of properties chris has.  Together, they would be saying that the property of being on dana is one of those that chris has.  This will be true if -- and only if -- chris is on dana.\n",
    "\n",
    "To actually work this out algebraically goes like this: The function `\\P.P(chris)` takes a predicate and calls it `P`.  The predicate it is being given is `\\x.on(x, dana)`.  So, let's call that predicate `P`, and substitute it in for `P`.  This gives us `\\x.on(x, dana)(chris)`.  The function represented by `\\x.on(x, dana)` takes an individual and calls it `x`.  The argument \"chris\" is an individual and is being given to that function.  So, we take chris and name it `x`, then substitute chris in for `x`, yielding: `on(chris, dana)`.  This procedure is sometimes called \"lambda conversion\".  It's pretty straightforward once you grasp what it is doing.\n",
    "\n",
    "expression  |  note\n",
    "-------------------|--\n",
    "\\P.P(chris) ( \\x.on(x, dana) )\n",
    " | replace P after . with \\x.on(x, dana)\n",
    "\\x.on(x, dana)(chris)       | \n",
    " | replace x after . with chris\n",
    "on(chris, dana) |\n",
    "\n",
    "Put yet one more way, imagine you have functions.\n",
    "\n",
    "```python\n",
    "def subj_chris(fn):\n",
    "  return fn(chris)\n",
    "\n",
    "def vp_on_dana(x):\n",
    "  return((x, 'd') in m.valuation['on'])\n",
    "```\n",
    "\n",
    "Here, `vp_on_dana(x)` is a predicate that is true for any `x` you give it that turns out to be on dana.  And `subj_chris(fn)` is a function that takes a function and applies it to chris.  So, combining the two is just `subj_chris(vp_on_dana)`, which will wind up applying `vp_on_dana` to `chris` and be true if chris is on dana.\n",
    "\n",
    "And this is how we got the `SEM` feature of `S` up at the top to be just `on(chris, dana)`.  It substituted `\\x.on(x, dana)` in for `P`, and then substituted chris in for `x`, leading to `on(chris, dana)`.  And that, depending on the configuration of the model at the moment, could either be true or false.\n",
    "\n",
    "That should I think be good enough to see the basics of how the semantics combines, if it wasn't already clear from class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSEIYe-eeuw3"
   },
   "source": [
    "Let's look a bit at that definition for \"on\".\n",
    "\n",
    "It's a bit hard to see in the abstract how we arrived at this particular formula to represent the semantic value of \"on\", but it's really kind of just an algebra problem.  We assume that \"on\" is a function that takes \"dana\" as an argument.  We know what the `SEM` feature of dana is (it is `\\P.P(dana)`), and we know what the combination needs to yield for the `SEM` feature of the `PP` node (`\\x.on(x, dana)`).\n",
    "\n",
    "What it actually says is: `\\X.\\x.X(\\y.on(x,y))`.  So when it combines, we label `\\P.P(dana)` as `X` and substitute it in.  This gives us:\n",
    "```\n",
    "\\x.( \\P.P(dana) (\\y.on(x,y)))\n",
    "     ^^^^^^^^^^________________ this was \"X\"\n",
    "```\n",
    "\n",
    "That's hard to unwind, but essentially, we're taking `\\y.on(x,y)` to be the argument of `\\P.P(dana)` and so we substitute `\\y.on(x,y)` in for `P`, resulting in:\n",
    "\n",
    "```\n",
    "\\x.( \\y.on(x,y) (dana))\n",
    "     ^^^^^^^^^^________________ this was \"P\"\n",
    "```\n",
    "\n",
    "Now, we substitute dana in for `y` and get:\n",
    "\n",
    "```\n",
    "\\x.on(x,dana)\n",
    "        ^^^^___________________ this was \"y\"\n",
    "```\n",
    "\n",
    "And that's as simplified as we can make it.  That is in fact the semantics we want, the property of being on dana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbDSpsvcWTiH"
   },
   "source": [
    "Happily, that's about as complicated as the semantics are going to get.  There is one other thing that's a little bit complicated, and those are the determiners \"a\" and \"every.\"  We want the robot to be able to parse a sentence like \"every block is on a square\", which means it needs to understand how to parse \"every block\".  \"Every block\" is a DP, it can be a subject of a sentence.  And \"block\" is a noun, \"every\" is a determiner.  So we need to work out what each of these pieces need to mean.\n",
    "\n",
    "In a sense, this is what one studies in Intermediate Semantics, and I can't cram all of that semester into this one project.  I'll try to give a quick rationale anyway.\n",
    "\n",
    "First, let's handle the nouns.  Those are pretty easy.  The semantics of the noun \"block\" is something that is true of any individual that is a block.  We have defined what the blocks are in the valuation function.  So, the `SEM` feature for \"block\" should just be `<\\x.block(x)>`, true of anything that the valuation function says is in \"block\".\n",
    "\n",
    "We'll just make a bunch of those rules, one per noun.  So that we don't have to type each one in (since they are all the same except for the noun itself), I'll use a little list comprehension to make them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "cLXWNWvmkluw"
   },
   "outputs": [],
   "source": [
    "nouns = ['block', 'ball', 'square', 'pyramid', 'thing']\n",
    "nounstring = [r\"NP[SEM=<\\y.{n}(y)>] -> '{n}'\".format(n=noun) for noun in nouns]\n",
    "gramspec['np'] = \"\\n\".join(nounstring) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4XiDq41X4b0"
   },
   "source": [
    "Here are the rules we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tksoM9lX-Gk",
    "outputId": "49f9ac59-f4e8-4027-bab8-83df221e708d"
   },
   "outputs": [],
   "source": [
    "print(gramspec['np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAw6C3j6X_-b"
   },
   "source": [
    "While we're here, we can do adjectives too.  The meaning of an adjective is really exactly the same as the meaning of a noun.  \"Red\" is true of any individual in the \"red\" set in the valuation function.  So we can define the adjectives the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VY48-YSSJTQG"
   },
   "source": [
    "### q3 (define the adjectives) ###\n",
    "\n",
    "**Question:** Build the adjectives in the same way we built the nouns.  The adjectives are odd, even, red, green, and blue, and the semantics is the same as for the nouns (so, even should be `<\\x.even(x)>`). BUT BEWARE. The English word for odd is \"odd\" but the definition in the valuation function calls it \"oddtastic\".  So I have defined that one separately for you.\n",
    "\n",
    "The autograder will check to make sure that all five adjectives yield a parse.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "3QrsOebNJTQM"
   },
   "outputs": [],
   "source": [
    "adjs = ['even', 'red', 'green', 'blue'] # skip 'odd', we will add that at the end\n",
    "\n",
    "adjstrings = ...\n",
    "...\n",
    "\n",
    "# add odd (special case: its key in the valuation function is \"oddtastic\")\n",
    "gramspec['adj'] = r\"Adj[SEM=<\\x.oddtastic(x)>] -> 'odd'\" + \"\\n\" + gramspec['adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v07NnS2YN85"
   },
   "source": [
    "Here are the adjective rules we constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4ssewn2YRSe",
    "outputId": "51133cf3-1abe-4f03-91b7-17e165bafb7e"
   },
   "outputs": [],
   "source": [
    "print(gramspec['adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvbvZhE_YUDj"
   },
   "source": [
    "A \"DP\" (determiner phrase, something that can be a subject or an object) is made of a determiner (like \"a\" or \"every\") and a noun phrase (like \"square\").\n",
    "\n",
    "So, the basic rule is:\n",
    "```\n",
    "DP -> Det NP\n",
    "```\n",
    "The determiners we will have are \"a\" (or \"an\") and \"every\".  So, for example, \"every block is on dana\".  We already know what \"block\" is (`\\x.block(x)`), and we know from before that \"is on dana\" works out to (`\\x.on(x,dana)`).  What \"every block is on dana\" means is that everything that has the first property (being a block) also has the second property (being on dana).  So, the definition of \"every\" is something that takes two properties, and is true if having the first property implies having the second property.\n",
    "\n",
    "This is put into the grammar specification below.  The determiner \"a(n)\" is also defined there, which I'll review just below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "oIiJNZ4LkO75"
   },
   "outputs": [],
   "source": [
    "gramspec['dp'] = r\"\"\"\n",
    "DP[SEM=<?det(?np)>] -> Det[SEM=?det] NP[SEM=?np]\n",
    "\"\"\"\n",
    "\n",
    "gramspec['d'] = r\"\"\"\n",
    "Det[SEM=<\\N Q.exists x.(N(x) & Q(x))>] -> 'a' | 'an'\n",
    "Det[SEM=<\\N Q.all x.(N(x) -> Q(x))>] -> 'every'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m44xwjLHgPnj"
   },
   "source": [
    "The meaning of \"a block is on dana\" is somewhat similar to \"every block is on dana.\" It too takes two properties (the property of being a block, and the property of being on dana), and it is true if there is something that has both properties.  If there is something that is a block and also is on dana, then it is true that \"a block is on dana.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "7YpCG8gqgyeu",
    "outputId": "38e05592-76bb-4080-ac90-f1dbaf077ef4"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"every block is on dana\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYsnmALqhkzd"
   },
   "source": [
    "Take a moment to look over the tree and see how this works.  You can see that the \"every\" node has a complicated semantic value that starts with `\\N`.  When we combine \"every\" with \"block\", the semantic value of \"block\" gets substituted in for \"N\", which you can see has happened in the node above it.  This step kind of \"peeled away\" the \\N by substituting in \"block\", leaving the next level in for the node above it.  The next level in starts with `\\Q`, and the semantic value of the VP is substituted in for `Q`, yielding the value at the top: for all individuals \"x\", if x is a block, then x is on dana.  That is, every block is on dana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPUwXHK4g5vH"
   },
   "source": [
    "One last thing to look at is how to get adjectives in there.  We defined the semantics of the adjectives, but we don't yet have a rule that puts them into the tree or integrates them with the rest of the semantics.\n",
    "\n",
    "Imagine that we wanted to say \"every green pyramid is on dana\".   The adjective \"green\" goes between the Det and the NP.  Moreover, you can have many adjectives in principle. We can model this by supposing that we attach adjectives to NPs, but the result is an NP.  That way, we can attach another adjective to the NP that resulted from combining an NP and an adjective.  The rule we want is like this:\n",
    "```\n",
    "NP -> Adj NP\n",
    "```\n",
    "As for the semantics, how is \"blue block\" related to \"block\"? Well, the blue blocks are just those blocks that are blue.  Or, the blue blocks are just those blue things that are blocks. Basically, it's just all those things that are both blue and blocks. So the semantics is just a conjunction of the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "x7FTEMUBg5GU"
   },
   "outputs": [],
   "source": [
    "gramspec['adjnp'] = r\"\"\"\n",
    "NP[SEM=<\\x.(?adj(x) & ?np(x))>] -> Adj[SEM=?adj] NP[SEM=?np]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "9qeBFX1p-1hA",
    "outputId": "40d2b105-cd79-492a-d19e-64eabd9008fd"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"every blue block is on an odd square\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8XeZr_ggm0N"
   },
   "source": [
    "Complicated, but it looks right.  (And notice that the translation of the English word \"odd\" uses the symbol \"oddtastic\", as desired.)  We could even see if it's true. Let's look at the world ourselves and see if it should be true.  Is every blue block on an odd square?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "3xINdLm__btH",
    "outputId": "f2bf174b-a6d6-4d43-fa0b-2757f9d38ee6"
   },
   "outputs": [],
   "source": [
    "reset_world()\n",
    "plot_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5FUUZmFAS9S"
   },
   "source": [
    "To get the semantics of the top node we ask the tree what its SEM feature is. We can then ask the model whether that formula is true given the current state of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4KlT3FPAKOh",
    "outputId": "52570a7c-96f4-4878-be86-89a16e03cac0"
   },
   "outputs": [],
   "source": [
    "expression = parses[0].label()['SEM']\n",
    "print(expression)\n",
    "print(m.satisfy(expression, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "N-s7BR2UBE9a",
    "outputId": "1110c8e8-4d41-45b2-85fc-423e79765134"
   },
   "outputs": [],
   "source": [
    "put_on('s7')\n",
    "pick_up('b')\n",
    "put_on('s1')\n",
    "plot_world()\n",
    "print(m.satisfy(expression, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ6WnFcsM5pl"
   },
   "source": [
    "# Extending beyond declarative clause types\n",
    "\n",
    "We are already at the point where we could build an interface to the robot that would allow us to type a statement and have the robot tell us whether it is true or not.  But we also want to introduce imperatives (so we can tell the robot to do something) and questions (so we can ask whether something is true).  In class we built the user interface first and then extended it after, but let's just plan ahead now and work out the grammar extensions.\n",
    "\n",
    "In a sense, we're going to \"cheat\" for both of these extensions.  That is, we're not going to do a deep syntactic analysis, we're just going to look at the specific types of sentences the robot needs to respond to and detemine how to parse them.\n",
    "\n",
    "For imperatives, we want to use sentences like \"take a green pyramid\".  These sentences lack a subject (or have a silent subject).  So, we have a VP made of \"take\" and an object, and nothing else in the S.  So, we can say something like: \"if a sentence has only a VP (that is, if it is missing its subject), then it is an imperative.\n",
    "\n",
    "For yes-no questions, we are going to rely on the fact that these sentences are all of the \"be...on\" type, and so forming a yes-no question (like \"is a green pyramid on a ball\") is accomplished by just reversing the subject and the copula \"is\".  So, we can say something like: \"if a sentence is VCOP DP VP, then it is a yes-no question.\"  Thinking about it just a bit further, we observe that the VP is itself not a normal VP, it is a VP from which the VCOP has been removed (it was put at the beginning).  Since the VP was just \"is\" and a PP before, it will in this case look like just a PP.\n",
    "\n",
    "To put this in the grammar, we just define some additional `S` nodes, for the different configurations.  For yes-no questions it is going to require defining a different VP as well.\n",
    "\n",
    "Simplistically, we need something like \n",
    "```\n",
    "S -> VCOP DP PP\n",
    "```\n",
    "for yes-no questions. This is not quite what we do in syntax classes, but it will do.  As far as the semantics go, we can define the semantics to be the same as they would be for a declarative, given that we will need to check those semantics in order to be able to answer \"Yes\" or \"No\".\n",
    "\n",
    "For imperatives, we need something like\n",
    "```\n",
    "# for put a blue block on an even square\n",
    "S -> V DP PP\n",
    "\n",
    "# for take a blue block\n",
    "S -> V DP\n",
    "```\n",
    "Again, not that well motivated in terms of theoretical syntax, but it matches what we see.  And it would not be that hard to make this look more like trees you'd make in a Syntax course, but it's not necessary for the present purposes.  For the semantics in imperatives, we won't bother computing the top node's semantics, since it wouldn't be used for anything even if we had computed it.\n",
    "\n",
    "The main additional thing we need to do is add a feature (`CT` for clause type) on the `S` node so that the parser can see it and react to it.  And add the transitive verb (`VTR`) \"take\" and the ditransitive verb (`VDT`) \"put\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "CCLf0nZJS6lW"
   },
   "outputs": [],
   "source": [
    "gramspec['s'] = r\"\"\"\n",
    "% start S\n",
    "S[CT=decl, SEM=<?subj(?vp)>] -> DP[SEM=?subj] VP[SEM=?vp]\n",
    "S[CT=ynq, SEM=<?subj(?pp)>] -> VCOP DP[SEM=?subj] PP[SEM=?pp]\n",
    "S[CT=imp] -> VTR DP\n",
    "S[CT=imp] -> VDT DP PP\n",
    "VTR -> 'take'\n",
    "VDT -> 'put'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0BQlkS_YC3e"
   },
   "source": [
    "Here is what we get for a \"take\" imperative, a \"put\" imperative, and a yes-no question. For simplicity, I'll omit the features and just display the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "VHFeWpxpXrlG",
    "outputId": "ff63d8d8-d3a9-483a-8733-7a61b6d662c5"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"take a blue block\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0], features=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "g5MubBD9X2Kk",
    "outputId": "bd697d55-f539-48ec-cba7-00c4a1dd8e45"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"put a blue block on an even square\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0], features=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "tX759WKUYJu5",
    "outputId": "a49321b3-ea33-486c-f1a7-f8c055be3783"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"is a blue block on an even square\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0], features=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFuch4FbYgaZ"
   },
   "source": [
    "# Finding important parts of parses\n",
    "\n",
    "The interface will get a sentence from the user, parse it, and then react appropriately.  In order to react appropriately it needs to be able to tell what the important properties of the sentence are.  We have defined the grammar to set the `CT` feature of the tree to be the clause type.  We can detect that in a way that is very parallel to how we ask for the `SEM` feature of the tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9E-OMyMZNQG",
    "outputId": "24cbc161-b7e3-4246-aa25-86992bec524d"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"is a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print(\"Clause type: \", first_parse.label()['CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WTlDDa3ZeW1",
    "outputId": "90e27d3f-0382-4a22-9ea3-8d028698909d"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"a blue block is on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print(\"Clause type: \", first_parse.label()['CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUu8FnmDkwzp",
    "outputId": "1efbc09e-5904-4765-faa2-82d57e6a76c9"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print(\"Clause type: \", first_parse.label()['CT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNoMaDKfZuTu"
   },
   "source": [
    "For declaratives and yes-no questions, we can determine whether to say \"True\" or \"Yes\" / \"False\" or \"No\" by evaluating the `SEM` value of the clause against the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-6I0mYxZ9fn",
    "outputId": "85f9d043-f95c-4243-f645-c1ba22d09f91"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"a blue block is on an odd square\".split()))\n",
    "first_parse = parses[0]\n",
    "expression = parses[0].label()['SEM']\n",
    "print('True') if m.satisfy(expression, g) else print('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foCY0QkcaqXN",
    "outputId": "d645271a-c951-4b86-86ff-235144b204f6"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"is a blue block on an odd square\".split()))\n",
    "first_parse = parses[0]\n",
    "expression = parses[0].label()['SEM']\n",
    "print('Yes') if m.satisfy(expression, g) else print('No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSM67XK8UU5M"
   },
   "source": [
    "For imperatives, we need to determine what the verb is, what the object is, and -- if the verb is ditransitive -- where the object will go.  As a reminder, here is what we have for \"take a block\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "id": "GkyZXtTAUfQn",
    "outputId": "5e728ffa-c446-49a7-f987-779ae8dbac2a"
   },
   "outputs": [],
   "source": [
    "full_spec = assemble_spec(gramspec)\n",
    "new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "parser = nltk.FeatureChartParser(new_grammar)\n",
    "words = \"take a block\".split()\n",
    "parses = list(parser.parse(words))\n",
    "svgling.draw_tree(convert_tree(parses[0], features=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGAbyDl4a3HL"
   },
   "source": [
    "The verb is going to be the first daughter of `S`, so we can treat the tree as a list and look for the first element.  The first element is the nonterminal node (`VTR` or `VDT`) and the first element of *that* is the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u64eA55FbJ-N",
    "outputId": "91049f56-8c29-45e8-e434-33090d9f6b80"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"take a blue block\".split()))\n",
    "first_parse = parses[0]\n",
    "print('Verb nonterminal node is: ', first_parse[0])\n",
    "print('Verb is: ', first_parse[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPXiGc-gbm6f",
    "outputId": "307826a5-a69a-4701-f93a-4abd583595d1"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print('Verb nonterminal node is: ', first_parse[0])\n",
    "print('Verb is: ', first_parse[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOBCxSMEbroD"
   },
   "source": [
    "The object is going to be the second element, for both types of verb.  This will have a `SEM` feature associated with it that will allow us to determine what it refers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3B2XoEZ1bzfl",
    "outputId": "978f6661-8417-407b-f890-31ec2c895ed2"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print(\"Object's SEM feature is: \", first_parse[1].label()['SEM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb0Aj8docSTs"
   },
   "source": [
    "What are the blue blocks? We can ask the model what the options are by asking it what values of `y` make the statement \"`y` is a blue block\" true.  Below, we use NLTK's semantics module to create a predicate `is_y` that is true of things that are y, we give that to the expression we got from the object's `SEM` feature, and then we use the model's `satisfiers()` function to determine which values of `y` make \"`y` is a blue block\" true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "479WCP7_c6CV",
    "outputId": "70b08e6a-a417-435a-8a3e-250db3428797"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "obj_sem = first_parse[1].label()['SEM']\n",
    "is_y = nltk.sem.Expression.fromstring(r\"\\x.(x=y)\")\n",
    "obj_is_y = nltk.sem.ApplicationExpression(obj_sem, is_y).simplify()\n",
    "options = m.satisfiers(obj_is_y, 'y', g)\n",
    "print(\"Options: \", options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT13Yxwke4Lw"
   },
   "source": [
    "The last thing we need to be able to figure out is where the object is to be put for the verb \"put\". To do this, we need to look at what the object of \"on\" is. Let's draw a tree, so we can trace through it visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "0FJZsEVdfHzU",
    "outputId": "24994630-8544-4fa5-e9d5-ac40e47f8eae"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put chris on a square\".split()))\n",
    "svgling.draw_tree(convert_tree(parses[0], features=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SWEZtoLfX1g"
   },
   "source": [
    "Looking at the tree, we can see that the `PP` is the third daughter of `S`, and the object is the second daughter of the `PP`.  So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QlMWTeifloa",
    "outputId": "d55a6fe6-a986-4e46-b4dd-4239bc228107"
   },
   "outputs": [],
   "source": [
    "parses = list(parser.parse(\"put a blue block on an even square\".split()))\n",
    "first_parse = parses[0]\n",
    "print(\"Target for put has a SEM feature of: \", first_parse[2][1].label()['SEM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PogpsdE-f85K"
   },
   "source": [
    "Let us consolidate the conclusions above into functions that we can use in the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "olCx3C_ugGW4"
   },
   "outputs": [],
   "source": [
    "def parse_sentence(gramspec, sentence):\n",
    "  full_spec = assemble_spec(gramspec)\n",
    "  new_grammar = grammar.FeatureGrammar.fromstring(full_spec)\n",
    "  parser = nltk.FeatureChartParser(new_grammar)\n",
    "  words = sentence.split()\n",
    "  parses = list(parser.parse(words))\n",
    "  return parses\n",
    "\n",
    "def clause_type(parse):\n",
    "  return parse.label()['CT']\n",
    "\n",
    "def clause_sem(parse):\n",
    "  return parse.label()['SEM']\n",
    "\n",
    "def object_sem(parse):\n",
    "  return parse[1].label()['SEM']\n",
    "\n",
    "def dp_options(dp_sem):\n",
    "  is_y = nltk.sem.Expression.fromstring(r\"\\x.(x=y)\")\n",
    "  dp_is_y = nltk.sem.ApplicationExpression(dp_sem, is_y).simplify()\n",
    "  options = m.satisfiers(dp_is_y, 'y', g)\n",
    "  return options\n",
    "\n",
    "def imp_verb(parse):\n",
    "  return parse[0][0]\n",
    "\n",
    "def check_truth(parse):\n",
    "  global m\n",
    "  g = nltk.Assignment(m.domain)\n",
    "  return m.satisfy(clause_sem(parse), g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mGXHwc43WHA7"
   },
   "source": [
    "### q4 (interpreting the target of put) ###\n",
    "\n",
    "**Question:** Add one more function called `target_sem(parse)` to those above that will find the semantic value for the target of \"put\".  For example, if the sentence were \"put a blue block on an even square\", as above, we want the `target_sem(parse)` function to return the `SEM` feature of the DP \"an even square\".  This is mostly just to ensure that you are following along.  You can model this on `object_sem(parse)` above, finding the node in the way we just did immediately above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "acVTmIOGWHA-"
   },
   "outputs": [],
   "source": [
    "def target_sem(parse):\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3C8N9obgqWE"
   },
   "source": [
    "Just to reassure ourselves that we have replicated what we did by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_rmxUREgu1l",
    "outputId": "f9b08e3f-6de6-416e-d2fa-11e2dbb96529"
   },
   "outputs": [],
   "source": [
    "parses = parse_sentence(gramspec, \"put a blue block on an even square\")\n",
    "first_parse = parses[0]\n",
    "print(\"Clause type: \", clause_type(first_parse))\n",
    "print(\"Verb (for imperative): \", imp_verb(first_parse))\n",
    "print(\"Object SEM: \", object_sem(first_parse))\n",
    "print(\"Object options: \", dp_options(object_sem(first_parse)))\n",
    "print(\"Target SEM: \", target_sem(first_parse))\n",
    "print(\"Target options: \", dp_options(target_sem(first_parse)))\n",
    "parses = parse_sentence(gramspec, \"dana is on a blue block\")\n",
    "first_parse = parses[0]\n",
    "print(\"Clause SEM: \", clause_sem(first_parse))\n",
    "print(\"This holds in the model? \", check_truth(first_parse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRc9oPKziVZ0"
   },
   "source": [
    "We now have assembled enough tools that we can write up a user interface to the robot pretty simply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyT-VqocihxT"
   },
   "source": [
    "# Talking to the robot\n",
    "\n",
    "Now we will write a short function that will collect a sentence from the user, parse it, and act on it.  In class we designed a little chat program that would operate in a loop, but here we'll define a function called `hey_robot()` that will take the sentence and act on it.\n",
    "\n",
    "> For fun, I've also included a definition of `chat()` that makes use of `hey_robot()` so that if you want to you can have what feels like a more interactive session with the robot.  In the `chat()` function, you type `bye` to quit.\n",
    "\n",
    "In `hey_robot()` there are two special \"magic commands\", one being `look` to show the world, and a third being `reset` to reset the world to its original state.\n",
    "\n",
    "In order to divide up the labor and make the architecture of the system flexible, we will define separate functions for the main input processor, and handlers for each of the clause types.\n",
    "\n",
    "When we collect the input from the user, we will force it to be lowercase and remove any `?` characters that the user might have added (i.e. to a yes-no question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "cD5tk3KO6qij"
   },
   "outputs": [],
   "source": [
    "def hey_robot(sentence):\n",
    "  sentence = sentence.lower().replace(\"?\", \"\")\n",
    "  if sentence == 'look':\n",
    "    plot_world()\n",
    "  elif sentence == 'reset':\n",
    "    reset_world()\n",
    "    print('World reset to initial state.')\n",
    "  else:\n",
    "    try:\n",
    "      parses = parse_sentence(gramspec, sentence)\n",
    "      first_parse = parses[0]\n",
    "      ct = clause_type(first_parse)\n",
    "      if ct == 'ynq':\n",
    "        do_ynq(first_parse)\n",
    "      elif ct == 'imp':\n",
    "        do_imp(first_parse)\n",
    "      else: # decl\n",
    "        do_decl(first_parse)\n",
    "    except Exception as e:\n",
    "      print(\"Error: {}\".format(e))\n",
    "      print(\"Sorry, what?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "oPnXTobZjn04"
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "  print(\"Type 'bye' to leave, 'look' to show the scene, 'reset' to reset the scene.\")\n",
    "  print()\n",
    "  sentence = 'look'\n",
    "  while sentence != 'bye':\n",
    "    hey_robot(sentence)\n",
    "    sentence = input(\"> \")\n",
    "  print(\"Bye!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK2b89rPYKKZ"
   },
   "source": [
    "The `hey_robot()` function above relies on functions `do_decl()`, `do_ynq()`, and `do_imp()`, but they have not been defined yet.  We can do the declarative and yes-no question ones pretty easily, those both just check whether the sentence is true and then print something appropriate.\n",
    "\n",
    "The `do_imp()` one is more complicated, so we'll for the moment just define it to say \"Out of order.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ZCRx1xHsltR4"
   },
   "outputs": [],
   "source": [
    "def do_decl(parse):\n",
    "  if check_truth(parse):\n",
    "    print('True')\n",
    "  else:\n",
    "    print('False')\n",
    "\n",
    "def do_ynq(parse):\n",
    "  if check_truth(parse):\n",
    "    print('Yes')\n",
    "  else:\n",
    "    print('No')\n",
    "\n",
    "def do_imp(parse):\n",
    "  print(\"Out of order.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otTRMjuqnV92"
   },
   "source": [
    "That is enough to talk to the robot initially, get it to say whether statements about the world are true or false, answer yes or no, and show or reset the world.  We left `do_imp()` defined to do nothing substantive yet, since we'll turn to that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuK6dMQ9nZFF",
    "outputId": "fee6d4dd-aadf-4906-874c-3b68893e024b"
   },
   "outputs": [],
   "source": [
    "hey_robot('reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utU1L66C8XYR",
    "outputId": "ac1ba020-e562-41e9-d101-0bf0e4162bfc"
   },
   "outputs": [],
   "source": [
    "hey_robot('a pyramid is on a ball')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCmPTTx28ctl",
    "outputId": "af75591e-0a04-4cae-c9d9-c6cb0a93d3e3"
   },
   "outputs": [],
   "source": [
    "hey_robot('is a blue thing on a square?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX9U8k0urCBV"
   },
   "source": [
    "For the imperatives, there are two different distinct things it can do: `take` and `put`.  We defined a couple of functions long ago that would pick things up and put them on things, but we'll incorporate what those functions did into what is happening here.  (Mostly, that is because now we need to contemplate the possibility that there are multiple options.)\n",
    "\n",
    "If we are trying to pick up an object, we can use `dp_options()` to determine what objects in the world match the description.  But not all objects in the world are takable.  Some objects are elements of the floor, and some objects are hidden under other objects. However, so long as there is some object that meets the description and is takable, we should take that object.  There might be multiple things we could take, we'll just pick one if so.\n",
    "\n",
    "If we are trying to put an object on another object, this is a compound action.  It requires picking up the object first and then putting it down.  Which also means that if we are already holding an object, we need to put that object down first.  The world has been strategically designed so that there are more squares in the floor than there are objects, so it is guaranteed that there will always be some square somewhere that is empty, so we can put something on an empty square and it will not obscure anything we might need to leave visible.  So, let's define something that will give us one of those empty squares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "yI3P4sB-vDLH"
   },
   "outputs": [],
   "source": [
    "def empty_square():\n",
    "  for square in floor:\n",
    "    if not whats_on(square):\n",
    "      return square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_UZO8p8vJJ8"
   },
   "source": [
    "We also need to know what the visible objects are.  These are the things that have nothing on top of them. So, we'll define a function that will give us the visible objects. We also want to exclude the object that is in the hand, since that can't be taken or used as a target for putting something on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Xx5RcESOwDDR"
   },
   "outputs": [],
   "source": [
    "def visible_things():\n",
    "  global m, obj_in_hand\n",
    "  return {obj for obj in m.domain - {obj_in_hand} if not whats_on(obj)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOZtZdgJwLWn"
   },
   "source": [
    "The visible objects are places we can put something. This is not quite the same as takable objects, because the squares of the floor count as visible objects but are not takable.  So, let's define the takable things too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "d00YexUYwdb_"
   },
   "outputs": [],
   "source": [
    "def takable_things():\n",
    "  global floor\n",
    "  return visible_things() - set(floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdhe-RBxwnR1",
    "outputId": "dfe95846-4300-4736-877b-84126825fea3"
   },
   "outputs": [],
   "source": [
    "print(\"Visible things: \", visible_things())\n",
    "print(\"Takable things: \", takable_things())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghwgInhKw4wX"
   },
   "source": [
    "And that's pretty much all we need to implement our imperative function.  We will split this up into a `do_put()` and a `do_take()` function because we actually need to do a `do_take()` as part of both actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "aOqL0lErrPJg"
   },
   "outputs": [],
   "source": [
    "def do_imp(parse):\n",
    "  global obj_in_hand, floor\n",
    "  verb = imp_verb(parse)\n",
    "  obj_options = dp_options(object_sem(parse))\n",
    "  if verb == 'take':\n",
    "    if do_take(obj_options):\n",
    "      print('Taken.')\n",
    "  elif verb == 'put':\n",
    "    if do_put(obj_options, parse):\n",
    "      print('Placed.')\n",
    "  else:\n",
    "    print(\"I don't understand what you are asking me to do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "O0CsFzx2zW3R"
   },
   "outputs": [],
   "source": [
    "def do_take(obj_options):\n",
    "  global obj_in_hand, floor\n",
    "  if len(obj_options) == 0:\n",
    "    print(\"There is no such thing to take.\")\n",
    "  else:\n",
    "    if obj_in_hand in obj_options:\n",
    "      print(\"Already holding a thing of the right kind.\")\n",
    "      return True\n",
    "    else:\n",
    "      if len(obj_options - set(floor)) == 0:\n",
    "        print(\"The floor is bolted down.\")\n",
    "      else:\n",
    "        takable = obj_options & takable_things()\n",
    "        if len(takable) == 0:\n",
    "          print(\"I cannot see such a thing to take.\")\n",
    "        else:\n",
    "          if obj_in_hand:\n",
    "            put_on(empty_square())\n",
    "          obj_to_take = list(takable)[0]\n",
    "          pick_up(obj_to_take)\n",
    "          return True\n",
    "  # unless we hit one of the success conditions, report that we failed.\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "UbBC4pHFz-x2"
   },
   "outputs": [],
   "source": [
    "def do_put(obj_options, parse):\n",
    "  if do_take(obj_options):\n",
    "    target_options = dp_options(target_sem(parse))\n",
    "    if len(target_options) == 0:\n",
    "      print(\"There is no such place to put anything.\")\n",
    "    else:\n",
    "      visible = target_options & visible_things()\n",
    "      if len(visible) == 0:\n",
    "        print(\"I cannot see such a place to put anything.\")\n",
    "      else:\n",
    "        target = list(visible)[0]\n",
    "        put_on(target)\n",
    "        return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf6IRnRQQJv4"
   },
   "source": [
    "At this point, you can play around with the robot a bit if you wish.  Below I've tried a couple of things that are of interest, and I've left some blank cells for your further entertainment as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "-F6GHcghavQn",
    "outputId": "7941e66d-8803-4e2f-92dd-37fed3cb71ee"
   },
   "outputs": [],
   "source": [
    "hey_robot('reset')\n",
    "hey_robot('put a red block on a blue pyramid')\n",
    "hey_robot('look')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMaL9HM_PnnH",
    "outputId": "722dcba8-69fd-4bb7-d550-08a06e6bc117"
   },
   "outputs": [],
   "source": [
    "hey_robot('take an odd square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxRydGBhPwy9",
    "outputId": "cfc4c41a-58e9-4ba0-eb51-b49c3f798313"
   },
   "outputs": [],
   "source": [
    "hey_robot('take a blue pyramid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "FvxHCOrKP1Tv",
    "outputId": "44f80634-38f7-43af-bcae-8ba7cd82d090"
   },
   "outputs": [],
   "source": [
    "hey_robot('take a pyramid')\n",
    "hey_robot('look')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "z10GxfjWP6XD",
    "outputId": "2c2696d5-da66-4d1f-b7e0-57a0da1e4a71"
   },
   "outputs": [],
   "source": [
    "hey_robot('take a blue thing')\n",
    "hey_robot('look')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "ke5TbLA2QWwP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "OqSHMUNNQWNT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "oc26Dpp9QWD9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "UpeLWglJQV7Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "lwVnsNNeQVyq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "Eu9n6osFQVp1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLaAasZOHaw6"
   },
   "source": [
    "# Pyramids are pointy\n",
    "\n",
    "We've got a pretty sophisticated system now, but there are lots of further directions you could take this if you desired.  For example, you might:\n",
    "\n",
    "- add \"under\"\n",
    "- add containers, object sizes, \"in\", \"empty\", \"full\"\n",
    "- make the world three dimensional and add predicates like \"beside\" and \"north of\", \"east of\".\n",
    "- add support for wh-questions so you can ask \"what is on a blue block?\" or \"how many green things are on an even square?\" or \"where is a red block?\"\n",
    "- add support for \"the\" so that it will assume that if you were previously talking about a green pyramid, subsequent reference to \"the pyramid\" will refer to the green pyramid. This requires implementing at least a limited amount of memory of the preceding discourse.\n",
    "- add memory of name assignments and a way to name things so you can, e.g. \"call the red block andy\" and then refer to it as \"andy\" for the rest of the conversation\n",
    "- add planning support so that if you try to pick up something that is not visible, the robot will first clear off the surface to make it visible, and then pick it up.\n",
    "- add support for multi-step actions so you can \"put every blue thing on an even square\"\n",
    "\n",
    "I will ask you to make just one extension here, to help convince yourself that you kind of understand how this works. The goal is going to be to prevent the robot from putting something on a pyramid.  Because pyramids are pointy, the thing would just fall off.\n",
    "\n",
    "> Even this could be moderately sophisticated.  The simple version is just to prevent putting anything on a pyramid altogether.  But you could also, for example, permit something on a pyramid just in case it is next to an object it could lean on.  Though in that case, probably the object should fall off into a neighboring column if the support is removed. Etc.  To begin with, just prevent anything from being placed on a pyramid at all, in order to satisfy the autograder.  If you would like to elaborate afterwards, feel free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cRL5BRql8FEo"
   },
   "source": [
    "### q5 (you can't put something on a pyramid) ###\n",
    "\n",
    "**Question:** This one is pretty free form.  Make some modifications so that when we try to get the robot to put an object on a pyramid it will refuse to do so.  Make this happen in whatever way you'd like; the autograder will try to put something on a pyramid and then check to be sure that the world has not changed.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "MAbUkCCJXG3R"
   },
   "outputs": [],
   "source": [
    "# Put whatever function redefinitions you need to put in here.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPW9A-PEXv7B"
   },
   "source": [
    "## Submission instructions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqO43UrDXzyJ"
   },
   "source": [
    "Go to File at the upper left of this web page and click \"Download .ipynb\" to download a copy of this.  Then go to Gradescope to submit the homework, and drag the .ipynb file in.  That should be all you need to do.  The autograder will run, but if your tests all passed in here, they should pass there as well.\n",
    "\n",
    "There are no other tests here, but if you want to add stuff to the end of the notebook to implement other things, feel free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOMSpwT8YK3s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lx694s21-hw3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
